{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e",
   "metadata": {
    "id": "25d7736c-ba17-4aff-b6bb-66eba20fbf4e"
   },
   "source": [
    "# Lab | Data Structuring and Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986",
   "metadata": {
    "id": "a2cdfc70-44c8-478c-81e7-2bc43fdf4986"
   },
   "source": [
    "## Challenge 1: Combining & Cleaning Data\n",
    "\n",
    "In this challenge, we will be working with the customer data from an insurance company, as we did in the two previous labs. The data can be found here:\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\n",
    "\n",
    "But this time, we got new data, which can be found in the following 2 CSV files located at the links below.\n",
    "\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\n",
    "- https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\n",
    "\n",
    "Note that you'll need to clean and format the new data.\n",
    "\n",
    "Observation:\n",
    "- One option is to first combine the three datasets and then apply the cleaning function to the new combined dataset\n",
    "- Another option would be to read the clean file you saved in the previous lab, and just clean the two new files and concatenate the three clean datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d06e3-92c7-4105-ac72-536db98d3244",
   "metadata": {
    "id": "492d06e3-92c7-4105-ac72-536db98d3244"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d62b6f5-0535-4bf8-9b26-3e42ab946eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Load the data from the three CSV files\n",
    "\"\"\"\n",
    "url1 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file1.csv\"\n",
    "url2 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file2.csv\"\n",
    "url3 = \"https://raw.githubusercontent.com/data-bootcamp-v4/data/main/file3.csv\"\n",
    "\n",
    "file1 = pd.read_csv(url1)\n",
    "file2 = pd.read_csv(url2)\n",
    "file3 = pd.read_csv(url3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b76e59aa-f41b-47fc-9684-6140e5d5e034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(  Customer          ST GENDER             Education Customer Lifetime Value  \\\n",
       " 0  RB50392  Washington    NaN                Master                     NaN   \n",
       " 1  QZ44356     Arizona      F              Bachelor              697953.59%   \n",
       " 2  AI49188      Nevada      F              Bachelor             1288743.17%   \n",
       " 3  WW63253  California      M              Bachelor              764586.18%   \n",
       " 4  GA49547  Washington      M  High School or Below              536307.65%   \n",
       " \n",
       "     Income  Monthly Premium Auto Number of Open Complaints     Policy Type  \\\n",
       " 0      0.0                1000.0                    1/0/00   Personal Auto   \n",
       " 1      0.0                  94.0                    1/0/00   Personal Auto   \n",
       " 2  48767.0                 108.0                    1/0/00   Personal Auto   \n",
       " 3      0.0                 106.0                    1/0/00  Corporate Auto   \n",
       " 4  36357.0                  68.0                    1/0/00   Personal Auto   \n",
       " \n",
       "    Vehicle Class  Total Claim Amount  \n",
       " 0  Four-Door Car            2.704934  \n",
       " 1  Four-Door Car         1131.464935  \n",
       " 2   Two-Door Car          566.472247  \n",
       " 3            SUV          529.881344  \n",
       " 4  Four-Door Car           17.269323  ,\n",
       "   Customer          ST GENDER Education Customer Lifetime Value  Income  \\\n",
       " 0  GS98873     Arizona      F  Bachelor              323912.47%   16061   \n",
       " 1  CW49887  California      F    Master              462680.11%   79487   \n",
       " 2  MY31220  California      F   College              899704.02%   54230   \n",
       " 3  UH35128      Oregon      F   College             2580706.30%   71210   \n",
       " 4  WH52799     Arizona      F   College              380812.21%   94903   \n",
       " \n",
       "    Monthly Premium Auto Number of Open Complaints  Total Claim Amount  \\\n",
       " 0                    88                    1/0/00               633.6   \n",
       " 1                   114                    1/0/00               547.2   \n",
       " 2                   112                    1/0/00               537.6   \n",
       " 3                   214                    1/1/00              1027.2   \n",
       " 4                    94                    1/0/00               451.2   \n",
       " \n",
       "       Policy Type  Vehicle Class  \n",
       " 0   Personal Auto  Four-Door Car  \n",
       " 1    Special Auto            SUV  \n",
       " 2   Personal Auto   Two-Door Car  \n",
       " 3   Personal Auto     Luxury Car  \n",
       " 4  Corporate Auto   Two-Door Car  ,\n",
       "   Customer       State  Customer Lifetime Value             Education Gender  \\\n",
       " 0  SA25987  Washington              3479.137523  High School or Below      M   \n",
       " 1  TB86706     Arizona              2502.637401                Master      M   \n",
       " 2  ZL73902      Nevada              3265.156348              Bachelor      F   \n",
       " 3  KX23516  California              4455.843406  High School or Below      F   \n",
       " 4  FN77294  California              7704.958480  High School or Below      M   \n",
       " \n",
       "    Income  Monthly Premium Auto  Number of Open Complaints    Policy Type  \\\n",
       " 0       0                   104                          0  Personal Auto   \n",
       " 1       0                    66                          0  Personal Auto   \n",
       " 2   25820                    82                          0  Personal Auto   \n",
       " 3       0                   121                          0  Personal Auto   \n",
       " 4   30366                   101                          2  Personal Auto   \n",
       " \n",
       "    Total Claim Amount  Vehicle Class  \n",
       " 0          499.200000   Two-Door Car  \n",
       " 1            3.468912   Two-Door Car  \n",
       " 2          393.600000  Four-Door Car  \n",
       " 3          699.615192            SUV  \n",
       " 4          484.800000            SUV  )"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checcking the first few rows of each dataset to inspect the data structure and content\n",
    "file1.head(), file2.head(), file3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f1ecc-d53e-4bda-87dc-c0dd99133235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6482fbd-9b50-4fd8-b2ae-761c432e5aef",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'file1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m file1 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile1.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     27\u001b[0m file2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m file3 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile3.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'file1.csv'"
     ]
    }
   ],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Cleans the dataset by performing operations such as:\n",
    "    - Removing duplicates\n",
    "    - Filling or dropping missing values\n",
    "    - Standardizing column names\n",
    "    - Fixing data types\n",
    "    \"\"\"\n",
    "    # Standardizing column names\n",
    "    df.columns = df.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "    # Removing duplicates\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Handling missing values (example: filling with 'unknown' or dropping rows)\n",
    "    df = df.fillna('unknown')\n",
    "\n",
    "    # Fixing data types (example: ensuring numeric columns are correctly typed)\n",
    "    for col in df.select_dtypes(include=['object']).columns:\n",
    "        if df[col].str.isnumeric().all():\n",
    "            df[col] = pd.to_numeric(df[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Load the data\n",
    "file1 = pd.read_csv(\"file1.csv\")\n",
    "file2 = pd.read_csv(\"file2.csv\")\n",
    "file3 = pd.read_csv(\"file3.csv\")\n",
    "\n",
    "# Clean each dataset\n",
    "file1_cleaned = clean_data(file1)\n",
    "file2_cleaned = clean_data(file2)\n",
    "file3_cleaned = clean_data(file3)\n",
    "\n",
    "# Combine the cleaned datasets\n",
    "combined_data = pd.concat([file1_cleaned, file2_cleaned, file3_cleaned], ignore_index=True)\n",
    "\n",
    "# Perform a final cleaning on the combined dataset\n",
    "final_cleaned_data = clean_data(combined_data)\n",
    "\n",
    "# Save the final cleaned dataset to a CSV file\n",
    "final_cleaned_data.to_csv(\"final_cleaned_data.csv\", index=False)\n",
    "\n",
    "print(\"Data cleaning and combination complete. The final dataset has been saved as 'final_cleaned_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96888b0d-76a4-4a32-ba19-037024104418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31b8a9e7-7db9-4604-991b-ef6771603e57",
   "metadata": {
    "id": "31b8a9e7-7db9-4604-991b-ef6771603e57"
   },
   "source": [
    "# Challenge 2: Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b",
   "metadata": {
    "id": "a877fd6d-7a0c-46d2-9657-f25036e4ca4b"
   },
   "source": [
    "In this challenge, we will continue to work with customer data from an insurance company, but we will use a dataset with more columns, called marketing_customer_analysis.csv, which can be found at the following link:\n",
    "\n",
    "https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv\n",
    "\n",
    "This dataset contains information such as customer demographics, policy details, vehicle information, and the customer's response to the last marketing campaign. Our goal is to explore and analyze this data by performing data cleaning, formatting, and structuring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26",
   "metadata": {
    "id": "aa10d9b0-1c27-4d3f-a8e4-db6ab73bfd26"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a70f560d-9504-46c4-ade6-b0403d1f4c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/marketing_customer_analysis_clean.csv'\n",
    "df = pd.read_csv(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2368fef-ca09-4936-be07-ab795991be4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['unnamed:_0', 'customer', 'state', 'customer_lifetime_value',\n",
      "       'response', 'coverage', 'education', 'effective_to_date',\n",
      "       'employmentstatus', 'gender', 'income', 'location_code',\n",
      "       'marital_status', 'monthly_premium_auto', 'months_since_last_claim',\n",
      "       'months_since_policy_inception', 'number_of_open_complaints',\n",
      "       'number_of_policies', 'policy_type', 'policy', 'renew_offer_type',\n",
      "       'sales_channel', 'total_claim_amount', 'vehicle_class', 'vehicle_size',\n",
      "       'vehicle_type', 'month'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc9ab298-66c7-4c08-a6cf-3ce1cb2a2419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   unnamed:_0 customer       state  customer_lifetime_value response  \\\n",
      "0           0  DK49336     Arizona              4809.216960       No   \n",
      "1           1  KX64629  California              2228.525238       No   \n",
      "2           2  LZ68649  Washington             14947.917300       No   \n",
      "3           3  XL78013      Oregon             22332.439460      Yes   \n",
      "4           4  QA50777      Oregon              9025.067525       No   \n",
      "\n",
      "   coverage education effective_to_date employmentstatus gender  ...  \\\n",
      "0     Basic   College        2011-02-18         Employed      M  ...   \n",
      "1     Basic   College        2011-01-18       Unemployed      F  ...   \n",
      "2     Basic  Bachelor        2011-02-10         Employed      M  ...   \n",
      "3  Extended   College        2011-01-11         Employed      M  ...   \n",
      "4   Premium  Bachelor        2011-01-17    Medical Leave      F  ...   \n",
      "\n",
      "   number_of_policies     policy_type        policy  renew_offer_type  \\\n",
      "0                   9  Corporate Auto  Corporate L3            Offer3   \n",
      "1                   1   Personal Auto   Personal L3            Offer4   \n",
      "2                   2   Personal Auto   Personal L3            Offer3   \n",
      "3                   2  Corporate Auto  Corporate L3            Offer2   \n",
      "4                   7   Personal Auto   Personal L2            Offer1   \n",
      "\n",
      "   sales_channel  total_claim_amount  vehicle_class  vehicle_size  \\\n",
      "0          Agent          292.800000  Four-Door Car       Medsize   \n",
      "1    Call Center          744.924331  Four-Door Car       Medsize   \n",
      "2    Call Center          480.000000            SUV       Medsize   \n",
      "3         Branch          484.013411  Four-Door Car       Medsize   \n",
      "4         Branch          707.925645  Four-Door Car       Medsize   \n",
      "\n",
      "  vehicle_type month  \n",
      "0            A     2  \n",
      "1            A     1  \n",
      "2            A     2  \n",
      "3            A     1  \n",
      "4            A     1  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(url)\n",
    "\n",
    "# Fill missing numerical values with the median for relevant columns\n",
    "numerical_columns = ['customer_lifetime_value', 'income', 'monthly_premium_auto', \n",
    "                     'months_since_last_claim', 'months_since_policy_inception', \n",
    "                     'number_of_open_complaints', 'number_of_policies', 'total_claim_amount']\n",
    "\n",
    "# Loop through numerical columns and fill missing values with their respective medians\n",
    "for column in numerical_columns:\n",
    "    if column in df.columns:\n",
    "        df[column] = df[column].fillna(df[column].median())\n",
    "\n",
    "# Drop duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Verify the result\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b2de9-dd06-4993-8950-e27ef89c1001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, \n",
    "#create a summary table showing the total revenue for each sales channel (branch, call center, web, and email). \n",
    "#Round the total revenue to 2 decimal points. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcd13af3-49fc-4ff1-a7b3-d64161a84b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Sales Channel  Total Revenue\n",
      "0         Agent     1810226.82\n",
      "1        Branch     1301204.00\n",
      "2   Call Center      926600.82\n",
      "3           Web      706600.04\n",
      "\n",
      "Sorted Revenue Table (Descending):\n",
      "   Sales Channel  Total Revenue\n",
      "0         Agent     1810226.82\n",
      "1        Branch     1301204.00\n",
      "2   Call Center      926600.82\n",
      "3           Web      706600.04\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create a pivot table to summarize total revenue for each sales channel\n",
    "pivot_table = df.pivot_table(\n",
    "    index='sales_channel',\n",
    "    values='total_claim_amount',\n",
    "    aggfunc='sum'\n",
    ").round(2)\n",
    "\n",
    "# Resetting the index for better readability\n",
    "pivot_table = pivot_table.reset_index()\n",
    "pivot_table.columns = ['Sales Channel', 'Total Revenue']\n",
    "\n",
    "# Display the summary table\n",
    "print(pivot_table)\n",
    "\n",
    "# Sort the pivot table by total revenue in descending order for insights\n",
    "sorted_pivot_table = pivot_table.sort_values(by='Total Revenue', ascending=False)\n",
    "print(\"\\nSorted Revenue Table (Descending):\\n\", sorted_pivot_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bbe163-37c2-4f10-93de-915aa53db876",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de3381a2-b95a-459f-beb0-1812be6277e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education gender  Bachelor  College   Doctor  High School or Below   Master\n",
      "0              F   7874.27  7748.82  7328.51               8675.22  8157.05\n",
      "1              M   7703.60  8052.46  7415.33               8149.69  8168.83\n"
     ]
    }
   ],
   "source": [
    "# pivot table to show the average customer lifetime value per gender and education level\n",
    "pivot_table = df.pivot_table(\n",
    "    index='gender',\n",
    "    columns='education',\n",
    "    values='customer_lifetime_value',\n",
    "    aggfunc='mean'\n",
    ").round(2)\n",
    "\n",
    "pivot_table = pivot_table.reset_index()\n",
    "\n",
    "# Display the pivot table\n",
    "print(pivot_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df35fd0d-513e-4e77-867e-429da10a9cc7",
   "metadata": {
    "id": "df35fd0d-513e-4e77-867e-429da10a9cc7"
   },
   "source": [
    "1. You work at the marketing department and you want to know which sales channel brought the most sales in terms of total revenue. Using pivot, create a summary table showing the total revenue for each sales channel (branch, call center, web, and mail).\n",
    "Round the total revenue to 2 decimal points.  Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640993b2-a291-436c-a34d-a551144f8196",
   "metadata": {
    "id": "640993b2-a291-436c-a34d-a551144f8196"
   },
   "source": [
    "2. Create a pivot table that shows the average customer lifetime value per gender and education level. Analyze the resulting table to draw insights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c7f2e5-3d90-43e5-be33-9781b6069198",
   "metadata": {
    "id": "32c7f2e5-3d90-43e5-be33-9781b6069198"
   },
   "source": [
    "## Bonus\n",
    "\n",
    "You work at the customer service department and you want to know which months had the highest number of complaints by policy type category. Create a summary table showing the number of complaints by policy type and month.\n",
    "Show it in a long format table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291",
   "metadata": {
    "id": "e3d09a8f-953c-448a-a5f8-2e5a8cca7291"
   },
   "source": [
    "*In data analysis, a long format table is a way of structuring data in which each observation or measurement is stored in a separate row of the table. The key characteristic of a long format table is that each column represents a single variable, and each row represents a single observation of that variable.*\n",
    "\n",
    "*More information about long and wide format tables here: https://www.statology.org/long-vs-wide-data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a069e0b-b400-470e-904d-d17582191be4",
   "metadata": {
    "id": "3a069e0b-b400-470e-904d-d17582191be4"
   },
   "outputs": [],
   "source": [
    "# Your code goes here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89358d6e-1e54-46d0-9b73-46e5532eef34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      policy_type Month  Number of Complaints\n",
      "0  Corporate Auto     1            443.434952\n",
      "1   Personal Auto     1           1727.605722\n",
      "2    Special Auto     1             87.074049\n",
      "3  Corporate Auto     2            385.208135\n",
      "4   Personal Auto     2           1453.684441\n",
      "5    Special Auto     2             95.226817\n"
     ]
    }
   ],
   "source": [
    "# Create a summary table showing the number of complaints by policy type and month in a long format\n",
    "summary_table = df.pivot_table(\n",
    "    index='policy_type',\n",
    "    columns='month',\n",
    "    values='number_of_open_complaints',\n",
    "    aggfunc='sum'\n",
    ").reset_index()\n",
    "\n",
    "# Convert the table to long format\n",
    "long_format_table = pd.melt(\n",
    "    summary_table,\n",
    "    id_vars=['policy_type'],\n",
    "    var_name='Month',\n",
    "    value_name='Number of Complaints'\n",
    ")\n",
    "\n",
    "# Display the long format table\n",
    "print(long_format_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df057e-d233-4e4b-b2fb-a3509b403135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
